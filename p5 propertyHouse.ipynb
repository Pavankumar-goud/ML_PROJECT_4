{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNL1qLd4+RvWpoVI3bsP2Pt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install --upgrade scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gks1nXGxADa7","executionInfo":{"status":"ok","timestamp":1735552690129,"user_tz":-330,"elapsed":5138,"user":{"displayName":"N Pavan kumar Goud","userId":"01456300631262985586"}},"outputId":"8dd0cdf5-5df3-43ea-d3c2-750cc42b1d14"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6l5uaqVrHYw","executionInfo":{"status":"ok","timestamp":1735550307401,"user_tz":-330,"elapsed":534932,"user":{"displayName":"N Pavan kumar Goud","userId":"01456300631262985586"}},"outputId":"b0b17430-c420-4c07-832b-268bf91566a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["No missing values in y_train.\n","Fitting 10 folds for each of 10 candidates, totalling 100 fits\n","Validation ROC AUC: 0.7656343898070033\n","submission file created:project_5 submission.csv\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold\n","from sklearn.metrics import roc_auc_score\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.pipeline import Pipeline\n","\n","# Load the data\n","datafile_train = \"/content/Property_train.csv\"\n","datafile_test = \"/content/Property_test_share.csv\"\n","bd_train = pd.read_csv(datafile_train)\n","bd_test = pd.read_csv(datafile_test)\n","\n","# Target column and feature engineering\n","target = 'Junk'\n","bd_train['data'] = 'train'\n","bd_test['data'] = 'test'\n","all_data = pd.concat([bd_train, bd_test], axis=0, sort=False)\n","\n","# Handle missing numeric data and convert columns to numeric\n","cat_to_numeric = ['PriceIndex'+str(i) for i in range(1, 10)]\n","for col in cat_to_numeric:\n","    all_data[col] = pd.to_numeric(all_data[col], errors='coerce')\n","    all_data[col] = all_data[col].fillna(all_data.loc[all_data['data'] == 'train', col].median())\n","\n","# Encoding categorical features\n","cat_cols = ['InteriorsStyle', 'ListDate', 'Material', 'Agency', 'AreaIncomeType',\n","            'EnvRating', 'PRIMEUNIT', 'Channel', 'PlotType', 'Architecture',\n","            'Region', 'SubModel', 'Facade', 'State', 'RegionType', 'Zip']\n","\n","# Apply one-hot encoding for the categorical columns with more than 1000 occurrences\n","for col in cat_cols:\n","    k = all_data[col].value_counts()\n","    cats = k[k >= 1000].index[:-1]  # Keep categories with at least 1000 occurrences\n","    for cat in cats:\n","        name = col + '_' + str(cat)\n","        all_data[name] = (all_data[col] == cat).astype(int)\n","\n","    # Drop original categorical column\n","    del all_data[col]\n","\n","# Separate train and test datasets\n","x_train = all_data.drop([target, 'data'], axis=1)[all_data['data'] == 'train']\n","y_train = all_data[target][all_data['data'] == 'train']\n","x_test = all_data.drop([target, 'data'], axis=1)[all_data['data'] == 'test']\n","\n","# Check for missing values and drop them if present\n","if y_train.isnull().sum() > 0:\n","    print(f\"Dropping {y_train.isnull().sum()} rows with missing target values.\")\n","    x_train = x_train[y_train.notna()]\n","    y_train = y_train[y_train.notna()]\n","else:\n","    print(\"No missing values in y_train.\")\n","\n","# Check if x_train or y_train is empty after filtering\n","if x_train.empty or y_train.empty:\n","    print(\"x_train or y_train is empty after filtering, adjust data preprocessing.\")\n","else:\n","    # Split the dataset into training and validation sets\n","    X_train, X_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","\n","    # Define the model: GradientBoostingClassifier\n","    pipeline = Pipeline([\n","        ('classifier', GradientBoostingClassifier(random_state=42))\n","    ])\n","\n","    # Hyperparameter grid for RandomizedSearchCV\n","    params = {\n","        'classifier__n_estimators': [100, 200, 300],  # Number of boosting stages\n","        'classifier__learning_rate': [0.01, 0.1, 0.2],  # Step size shrinking\n","        'classifier__max_depth': [3, 5, 7],  # Depth of each tree\n","        'classifier__subsample': [0.8, 1.0],  # Fraction of samples used for fitting trees\n","        'classifier__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n","        'classifier__max_features': ['auto', 'sqrt', 'log2']  # Features to consider for splits\n","    }\n","\n","    # RandomizedSearchCV with Stratified K-Folds cross-validation\n","    rs = RandomizedSearchCV(pipeline, param_distributions=params, n_iter=10, scoring='roc_auc', cv=StratifiedKFold(n_splits=10), n_jobs=-1, verbose=20, random_state=42)\n","\n","    # Fit the model using RandomizedSearchCV\n","    rs.fit(X_train, y_train)\n","\n","    # Validate the model on the validation set\n","    y_pred_valid = rs.predict_proba(X_valid)[:, 1]\n","    roc_auc = roc_auc_score(y_valid, y_pred_valid)\n","    print(f\"Validation ROC AUC: {roc_auc}\")\n","\n","    # Predict on the test set and prepare submission\n","    submissions = pd.DataFrame({'Junk': rs.predict_proba(x_test)[:, 1]})\n","\n","    # Save the submission to a CSV file\n","    submissions.to_csv(\"project_5 submission.csv\", index=False)\n","    print(\"submission file created:project_5 submission.csv\")\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"4MNz0wmWsmTW","executionInfo":{"status":"ok","timestamp":1735553880344,"user_tz":-330,"elapsed":540,"user":{"displayName":"N Pavan kumar Goud","userId":"01456300631262985586"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UOfbFYsOCS_A"},"execution_count":null,"outputs":[]}]}